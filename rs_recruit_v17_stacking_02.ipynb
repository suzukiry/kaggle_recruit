{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contributions from:\n",
    "DSEverything - Mean Mix - Math, Geo, Harmonic (LB 0.493) \n",
    "https://www.kaggle.com/dongxu027/mean-mix-math-geo-harmonic-lb-0-493\n",
    "JdPaletto - Surprised Yet? - Part2 - (LB: 0.503)\n",
    "https://www.kaggle.com/jdpaletto/surprised-yet-part2-lb-0-503\n",
    "hklee - weighted mean comparisons, LB 0.497, 1ST\n",
    "https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st\n",
    "\n",
    "Also all comments for changes, encouragement, and forked scripts rock\n",
    "\n",
    "Keep the Surprise Going\n",
    "\"\"\"\n",
    "\n",
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('../../../mltestdata/05_recruit/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../../../mltestdata/05_recruit/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../../../mltestdata/05_recruit/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../../../mltestdata/05_recruit/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../../../mltestdata/05_recruit/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../../../mltestdata/05_recruit/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../../../mltestdata/05_recruit/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../../../mltestdata/05_recruit/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "#sure it can be compressed...\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(10):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "# NEW FEATURES FROM JMBULL\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "for c, dtype in zip(train.columns, train.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        test[c] = test[c].astype(np.float32)\n",
    "\n",
    "combine = [train, test]\n",
    "gw_list = ['2016-04-29','2016-04-30','2016-05-01','2016-05-02','2016-05-03','2016-05-04','2016-05-05','2017-04-29','2017-04-30','2017-05-01','2017-05-02','2017-05-03','2017-05-04','2017-05-05']\n",
    "post_gw_list=['2016-05-06']\n",
    "train['gw_flg'] = 0\n",
    "train['post_gw_flg'] = 0\n",
    "test['gw_flg'] = 0\n",
    "test['post_gw_flg'] = 0\n",
    "update_gw_list = [[\"0\" for i in range(3)] for j in range(len(gw_list))]\n",
    "update_post_gw_list = [[\"0\" for i in range(3)] for j in range(len(post_gw_list))]\n",
    "\n",
    "from datetime import date\n",
    "for index, gw_date in enumerate(gw_list):\n",
    "    temp_list = gw_date.split(\"-\")\n",
    "    for col_i, temp_figure in enumerate(temp_list):\n",
    "        update_gw_list[index][col_i]=int(temp_figure)\n",
    "        \n",
    "    #print(\"{}  {}  {}\".format(update_list[index][0],update_list[index][1],update_list[index][2]))\n",
    "    \n",
    "for index, gw_date in enumerate(post_gw_list):\n",
    "    temp_list = gw_date.split(\"-\")\n",
    "    for col_i, temp_figure in enumerate(temp_list):\n",
    "        update_post_gw_list[index][col_i]=int(temp_figure)\n",
    "\n",
    "for dataset in combine:\n",
    "    for index in range(len(update_gw_list)):\n",
    "        dataset.loc[dataset.visit_date == date(update_gw_list[index][0],update_gw_list[index][1],update_gw_list[index][2]), 'gw_flg'] = 1\n",
    "        \n",
    "for dataset in combine:\n",
    "    for index in range(len(update_post_gw_list)):\n",
    "        dataset.loc[dataset.visit_date == date(update_post_gw_list[index][0],update_post_gw_list[index][1],update_post_gw_list[index][2]), 'post_gw_flg'] = 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=['visitors','air_store_id','visit_date','id']\n",
    "y_train=train['visitors']\n",
    "x_train=train.drop(drop_cols, axis=1)\n",
    "\n",
    "x_test=test.copy()\n",
    "x_test=x_test.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-fold CV with Out-of-Fold Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define Utility Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation function\n",
    "\n",
    "def rmsle(preds, true):\n",
    "    rmsle = np.sqrt(mean_squared_error(np.log1p(true), np.log1p(preds)))\n",
    "    return float(rmsle)\n",
    "\n",
    "def eval_rmsle(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a evaluation matrix \n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "RMSLE = make_scorer(rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Sklearn K-fold & OOF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modified cross-validation function copied from Yifan's cool kernel. \n",
    "### Source: https://www.kaggle.com/yifanxie/porto-seguro-tutorial-end-to-end-ensemble\n",
    "\n",
    "def cross_validate_sklearn(clf, x_train, y_train, x_test, kf, scale=False, verbose=True):\n",
    "    start_time=time.time()\n",
    "    \n",
    "    # initialise the size of out-of-fold train an test prediction\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "\n",
    "    # use the kfold object to generate the required folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        # generate training folds and validation fold\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[test_index, :]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # perform scaling if required i.e. for linear algorithms\n",
    "        if scale:\n",
    "            scaler = StandardScaler().fit(x_train_kf.values)\n",
    "            x_train_kf_values = scaler.transform(x_train_kf.values)\n",
    "            x_val_kf_values = scaler.transform(x_val_kf.values)\n",
    "            x_test_values = scaler.transform(x_test.values)\n",
    "        else:\n",
    "            x_train_kf_values = x_train_kf.values\n",
    "            x_val_kf_values = x_val_kf.values\n",
    "            x_test_values = x_test.values\n",
    "        \n",
    "        clf.fit(x_train_kf_values, np.log1p(y_train_kf.values))\n",
    "\n",
    "        val_pred=np.expm1(clf.predict(x_val_kf_values))\n",
    "\n",
    "        train_pred[test_index] += val_pred\n",
    "\n",
    "        y_test_preds = np.expm1(clf.predict(x_test_values))\n",
    "        test_pred += y_test_preds\n",
    "\n",
    "        fold_rmsle = eval_rmsle(np.log1p(y_val_kf.values), np.log1p(val_pred))\n",
    "\n",
    "        if verbose:\n",
    "            #print('fold cv {} AUC score is {:.6f}, Gini_Norm score is {:.6f}'.format(i, fold_auc, fold_gini_norm))\n",
    "            print('fold cv {} RMSLE score is {:.6f}'.format(i, fold_rmsle))\n",
    "\n",
    "    test_pred /= kf.n_splits\n",
    "\n",
    "    cv_rmsle = eval_rmsle(np.log1p(y_train), np.log1p(train_pred))\n",
    "        \n",
    "    #cv_score = [cv_auc, cv_gini_norm]\n",
    "    cv_score = [cv_rmsle]\n",
    "    if verbose:\n",
    "\n",
    "        print('cv RMSLE score is {:.6f}'.format(cv_rmsle))\n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    "    return cv_score, train_pred, test_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Xgboost K-fold & OOF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_xgb(params, x_train, y_train, x_test, kf,  verbose=True, verbose_eval=50, scoreonly=False):\n",
    "    start_time=time.time()\n",
    "    nround=[]\n",
    "    # the prediction matrix need to contains 3 columns, one for the probability of each class\n",
    "    #train_pred = np.zeros((x_train.shape[0],3))\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    # self-defined eval metric\n",
    "    # f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "    # binary error\n",
    "    def feval_rmsle(preds, train_data):\n",
    "        preds = np.expm1(preds)\n",
    "        true = np.expm1(train_data.get_label())\n",
    "        #return 'rmsle', rmsle(true, preds), False\n",
    "\n",
    "        return 'rmsle', rmsle(preds, true), False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "\n",
    "        #y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "        y_train_kf, y_val_kf = np.log1p(y_train[train_index]), np.log1p(y_train[val_index])\n",
    "        x_test_kf=x_test.copy()\n",
    "        \n",
    "        d_train = xgboost.DMatrix(x_train_kf, y_train_kf)\n",
    "        d_val=xgboost.DMatrix(x_val_kf, y_val_kf)\n",
    "        d_test = xgboost.DMatrix(x_test_kf)\n",
    "        \n",
    "        watchlist= [(d_train, \"train\"), (d_val, 'val')]\n",
    "        bst = xgboost.train(params=params, \n",
    "                            dtrain=d_train, \n",
    "                            num_boost_round=8000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            evals=watchlist, \n",
    "                            verbose_eval=verbose_eval)        \n",
    "        \n",
    "#        y_val_kf_preds=bst.predict(d_val, ntree_limit=bst.best_ntree_limit)\n",
    "        y_val_kf_preds=np.expm1(bst.predict(d_val, ntree_limit=bst.best_ntree_limit))\n",
    "        nround.append(bst.best_ntree_limit)\n",
    "        \n",
    "        train_pred[val_index] += y_val_kf_preds\n",
    "#        test_pred += np.expm1((bst.predict(x_test, ntree_limit=bst.best_ntree_limit)))\n",
    "        test_pred += np.expm1(bst.predict(d_test))\n",
    "        \n",
    "        \n",
    "        #fold_cv = log_loss(y_val_kf.values, y_val_kf_preds)\n",
    "        #fold_rmsle = rmsle(np.expm1(train_pred[val_index]),np.expm1(y_val_kf.values))\n",
    "        fold_rmsle = rmsle(train_pred[val_index],np.expm1(y_val_kf.values))\n",
    "        fold_cv = fold_rmsle\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} rmsle score is {:.6f}'.format(i, fold_cv))\n",
    "\n",
    "    test_pred = test_pred / kf.n_splits\n",
    "    #cv_score = log_loss(y_train, train_pred)\n",
    "    #cv_score = rmsle(np.expm1(train_pred), y_train)\n",
    "    cv_score = rmsle(train_pred, y_train)\n",
    "    \n",
    "    if verbose:\n",
    "        print('cv rmsle score is {:.6f}'.format(cv_score))    \n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    " \n",
    "    if scoreonly:\n",
    "        #return cv_score # for the purpose of bayesian optimisation, we only need to return the CV score\n",
    "        return cv_score\n",
    "    else:\n",
    "        return (cv_score,train_pred,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 LigthGBM K-fold & OOF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_lgb(params, x_train, y_train, x_test, \n",
    "                        kf, \n",
    "                        cat_features=[],\n",
    "                        verbose=True, verbose_eval=100, nseeds=1, df_input=True,\n",
    "                        early_stopping=100, num_boost_round=8000, scoreonly=False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "\n",
    "    # self-defined eval metric\n",
    "    # f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "    # binary error\n",
    "    def feval_rmsle(preds, train_data):\n",
    "        preds = np.expm1(preds)\n",
    "        true = np.expm1(train_data.get_label())\n",
    "\n",
    "        return 'rmsle', rmsle(preds, true), False\n",
    "       \n",
    "    if len(cat_features)==0: use_cat=False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)): # folds 1, 2 ,3 ,4, 5\n",
    "        # example: training from 1,2,3,4; validation from 5\n",
    "        if df_input:\n",
    "            x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "        else:\n",
    "            x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "\n",
    "        y_train_kf, y_val_kf = np.log1p(y_train[train_index]), np.log1p(y_train[val_index])\n",
    "\n",
    "        for seed in range(nseeds):\n",
    "            params['feature_fraction_seed'] = seed\n",
    "            params['bagging_seed'] = seed\n",
    "\n",
    "            if use_cat:\n",
    "                lgb_train = lgb.Dataset(x_train_kf, y_train_kf, categorical_feature=cat_features)\n",
    "                lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train, categorical_feature=cat_features)\n",
    "\n",
    "            else:\n",
    "                lgb_train = lgb.Dataset(x_train_kf, y_train_kf)\n",
    "                lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train)\n",
    "\n",
    "            gbm = lgb.train(params,\n",
    "                            lgb_train,\n",
    "                            num_boost_round=num_boost_round,\n",
    "                            valid_sets=[lgb_val],\n",
    "                            early_stopping_rounds=early_stopping,\n",
    "                            feval=feval_rmsle,\n",
    "                            verbose_eval=verbose_eval)\n",
    "\n",
    "            val_pred = np.expm1(gbm.predict(x_val_kf, num_iteration=gbm.best_iteration))\n",
    "            \n",
    "            train_pred[val_index] += val_pred\n",
    "            test_pred += np.expm1((gbm.predict(x_test, num_iteration=gbm.best_iteration)))\n",
    "\n",
    "                                \n",
    "        train_pred[val_index] = val_pred/nseeds\n",
    "\n",
    "        #fold_rmsle = rmsle(np.expm1(y_val_kf.values), train_pred[val_index])\n",
    "        fold_rmsle = rmsle(train_pred[val_index],np.expm1(y_val_kf.values))\n",
    "        if verbose:\n",
    "            print('fold cv {} RMSLE score is {:.6f}'.format(i, fold_rmsle))\n",
    "\n",
    "    test_pred = test_pred / (nseeds * kf.n_splits)\n",
    "    #cv_score = rmsle(y_train, train_pred)\n",
    "    cv_score = rmsle(train_pred, np.expm1(y_train))\n",
    "    \n",
    "    if verbose:\n",
    "        print('cv RMSLE score is {:.6f}'.format(cv_score))\n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    "    #return cv_score, np.expm1(train_pred),test_pred\n",
    "    \n",
    "    if scoreonly:\n",
    "        return cv_score\n",
    "    else:\n",
    "        return cv_score, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Level 2 ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1   GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate=0.2, random_state=3, n_estimators=200, subsample=0.8, max_depth =10　=> around 0.5\n",
    "params = {'learning_rate': 0.1, \n",
    "        'n_estimators': 375,\n",
    "         'max_depth' : 10,\n",
    "         'min_samples_leaf': 3}\n",
    "model1 = ensemble.GradientBoostingRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 RMSLE score is 0.491316\n",
      "fold cv 1 RMSLE score is 0.486795\n",
      "fold cv 2 RMSLE score is 0.483089\n",
      "fold cv 3 RMSLE score is 0.484583\n",
      "fold cv 4 RMSLE score is 0.483190\n",
      "cv RMSLE score is 20.703650\n",
      "it takes 6124.088 seconds to perform cross validation\n"
     ]
    }
   ],
   "source": [
    "outcomes =cross_validate_sklearn(model1, x_train, y_train ,x_test, kf, scale=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start...\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start...\\n\")\n",
    "\n",
    "lv1_gbm_train_pred=outcomes[1]\n",
    "lv1_gbm_test_pred=outcomes[2]\n",
    "\n",
    "lv1_gbm_train_pred=pd.DataFrame(columns=['visitors'], data=lv1_gbm_train_pred)\n",
    "lv1_gbm_test_pred=pd.DataFrame(columns=['visitors'], data=lv1_gbm_test_pred)\n",
    "\n",
    "lv1_gbm_train_pred.to_csv('lv1_gbm_train_pred.csv', index=False)\n",
    "lv1_gbm_test_pred.to_csv('lv1_gbm_test_pred.csv', index=False)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv1_lgb_train_pred = pd.read_csv('./lv1_lgb_train_pred.csv')\n",
    "lv1_lgb_test_pred = pd.read_csv('./lv1_lgb_test_pred.csv')\n",
    "\n",
    "lv1_knr_train_pred = pd.read_csv('./lv1_knr_train_pred.csv')\n",
    "lv1_knr_test_pred = pd.read_csv('./lv1_knr_test_pred.csv')\n",
    "\n",
    "lv1_xgb_train_pred = pd.read_csv('./lv1_xgb_train_pred.csv')\n",
    "lv1_xgb_test_pred = pd.read_csv('./lv1_xgb_test_pred.csv')\n",
    "\n",
    "lv1_rfr_train_pred = pd.read_csv('./lv1_rfr_train_pred.csv')\n",
    "lv1_rfr_test_pred = pd.read_csv('./lv1_rfr_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate L1 output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['gbm','lgb','knr','xgb','rfr']\n",
    "train_pred_df_list=[lv1_gbm_train_pred, lv1_lgb_train_pred, lv1_knr_train_pred, lv1_xgb_train_pred, lv1_rfr_train_pred]\n",
    "\n",
    "test_pred_df_list=[lv1_gbm_test_pred, lv1_lgb_test_pred, lv1_knr_test_pred, lv1_xgb_test_pred, lv1_rfr_test_pred]\n",
    "\n",
    "lv1_train_df=pd.DataFrame(columns=columns)\n",
    "lv1_test_df=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(columns)):\n",
    "    lv1_train_df[columns[i]]=train_pred_df_list[i]['visitors']\n",
    "    lv1_test_df[columns[i]]=test_pred_df_list[i]['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm</th>\n",
       "      <th>lgb</th>\n",
       "      <th>knr</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rfr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.169498</td>\n",
       "      <td>20.186493</td>\n",
       "      <td>19.627612</td>\n",
       "      <td>10.031622</td>\n",
       "      <td>20.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.308033</td>\n",
       "      <td>19.040413</td>\n",
       "      <td>18.991099</td>\n",
       "      <td>10.914748</td>\n",
       "      <td>18.261963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.069372</td>\n",
       "      <td>24.524543</td>\n",
       "      <td>23.468845</td>\n",
       "      <td>11.513679</td>\n",
       "      <td>30.183405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.419504</td>\n",
       "      <td>23.505738</td>\n",
       "      <td>17.624440</td>\n",
       "      <td>11.901163</td>\n",
       "      <td>21.146152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.882360</td>\n",
       "      <td>10.796744</td>\n",
       "      <td>13.756800</td>\n",
       "      <td>23.741966</td>\n",
       "      <td>13.492072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gbm        lgb        knr        xgb        rfr\n",
       "0  17.169498  20.186493  19.627612  10.031622  20.851900\n",
       "1  16.308033  19.040413  18.991099  10.914748  18.261963\n",
       "2  27.069372  24.524543  23.468845  11.513679  30.183405\n",
       "3  21.419504  23.505738  17.624440  11.901163  21.146152\n",
       "4  13.882360  10.796744  13.756800  23.741966  13.492072"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv1_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm</th>\n",
       "      <th>lgb</th>\n",
       "      <th>knr</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rfr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.850958</td>\n",
       "      <td>4.927308</td>\n",
       "      <td>6.199765</td>\n",
       "      <td>5.034050</td>\n",
       "      <td>2.481164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.194486</td>\n",
       "      <td>20.985203</td>\n",
       "      <td>21.752924</td>\n",
       "      <td>21.175813</td>\n",
       "      <td>20.729363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.778062</td>\n",
       "      <td>26.198808</td>\n",
       "      <td>26.588196</td>\n",
       "      <td>26.141714</td>\n",
       "      <td>24.485625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.267724</td>\n",
       "      <td>29.470553</td>\n",
       "      <td>27.608413</td>\n",
       "      <td>30.093324</td>\n",
       "      <td>24.867540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.377499</td>\n",
       "      <td>31.224496</td>\n",
       "      <td>26.794744</td>\n",
       "      <td>32.709636</td>\n",
       "      <td>27.772946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gbm        lgb        knr        xgb        rfr\n",
       "0   1.850958   4.927308   6.199765   5.034050   2.481164\n",
       "1  22.194486  20.985203  21.752924  21.175813  20.729363\n",
       "2  28.778062  26.198808  26.588196  26.141714  24.485625\n",
       "3  28.267724  29.470553  27.608413  30.093324  24.867540\n",
       "4  30.377499  31.224496  26.794744  32.709636  27.772946"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv1_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Level 2 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'num_leaves': int(242.70662305751688), \n",
    "    'max_depth': int(48.434894524736237), \n",
    "    'learning_rate': 0.22739737221785333, \n",
    "    'scale_pos_weight': 4449.6905120668471, \n",
    "    'min_sum_hessian_in_leaf': 2.9535851736769945, \n",
    "    'subsample': 0.78319355511875155, \n",
    "    'colsample_bytree': 0.60980110433768919, \n",
    "    'feature_fraction': 0.38725837624747139, \n",
    "    'bagging_fraction': 0.25993005950069908, \n",
    "    'bagging_freq': int(0.0063304070505429966), \n",
    "    'lambda_l1': 0.10468672203086582, \n",
    "    'lambda_l2': 0.73311141753276088, \n",
    "    'n_estimators': 7.574050255399829, \n",
    "    'reg_lambda': 0.7867690387142483, \n",
    "    'min_gain_to_split': 0.32711184887807354} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 RMSLE score is 0.477037\n",
      "fold cv 1 RMSLE score is 0.472756\n",
      "fold cv 2 RMSLE score is 0.469766\n",
      "fold cv 3 RMSLE score is 0.470899\n",
      "fold cv 4 RMSLE score is 0.469273\n",
      "cv RMSLE score is 0.471958\n",
      "it takes 51.440 seconds to perform cross validation\n"
     ]
    }
   ],
   "source": [
    "lgb_lv2_outcomes=cross_validate_lgb(lgb_params,lv1_train_df, y_train ,lv1_test_df,kf, verbose_eval=False)\n",
    "\n",
    "lgb_lv2_cv=lgb_lv2_outcomes[0]\n",
    "lgb_lv2_train_pred=lgb_lv2_outcomes[1]\n",
    "lgb_lv2_test_pred=lgb_lv2_outcomes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_lv2_train_pred_df=pd.DataFrame(columns=['visitors'], data=lgb_lv2_train_pred)\n",
    "lgb_lv2_test_pred_df=pd.DataFrame(columns=['visitors'], data=lgb_lv2_test_pred)\n",
    "\n",
    "lgb_lv2_train_pred_df.to_csv('lv2_lgb_train_pred.csv', index=False)\n",
    "lgb_lv2_test_pred_df.to_csv('lv2_lgb_test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Level 2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 RMSLE score is 0.478081\n",
      "fold cv 1 RMSLE score is 0.473846\n",
      "fold cv 2 RMSLE score is 0.470958\n",
      "fold cv 3 RMSLE score is 0.471976\n",
      "fold cv 4 RMSLE score is 0.470127\n",
      "cv RMSLE score is 20.460432\n",
      "it takes 795.987 seconds to perform cross validation\n"
     ]
    }
   ],
   "source": [
    "rf_lv2=RandomForestRegressor(max_depth=5,\n",
    "                            n_estimators=500,#100 too low\n",
    "                            min_samples_leaf=50,\n",
    "                            min_samples_split=10\n",
    "                           )\n",
    "\n",
    "rf_lv2_outcomes = cross_validate_sklearn(rf_lv2, lv1_train_df, y_train ,lv1_test_df, kf, \n",
    "                                            scale=False, verbose=True)\n",
    "rf_lv2_cv=rf_lv2_outcomes[0]\n",
    "rf_lv2_train_pred=rf_lv2_outcomes[1]\n",
    "rf_lv2_test_pred=rf_lv2_outcomes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lv2_train_pred_df=pd.DataFrame(columns=['visitors'], data=rf_lv2_train_pred)\n",
    "rf_lv2_test_pred_df=pd.DataFrame(columns=['visitors'], data=rf_lv2_test_pred)\n",
    "\n",
    "rf_lv2_train_pred_df.to_csv('lv2_rf_train_pred.csv', index=False)\n",
    "rf_lv2_test_pred_df.to_csv('lv2_rf_test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Level 2 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': int(9.6075334961758525), \n",
    "    'learning_rate': 0.12750069121004876, \n",
    "    'subsample': 0.70746966313901982, \n",
    "    'colsample_bytree': 0.91300804206695696, \n",
    "    'gamma': 0.79704305097433081, \n",
    "    'min_child_weight': 11.84689258578884, \n",
    "    'max_delta_step': 2.4269823914863409, \n",
    "    'n_estimators': 24.064145942538754, \n",
    "    'min_samples_split': 11.528636630859337, \n",
    "    'max_features': 0.74184703574431088\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xgboost...\n",
      "[0]\ttrain-rmse:2.1746\tval-rmse:2.18104\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.457013\tval-rmse:0.477576\n",
      "[100]\ttrain-rmse:0.450998\tval-rmse:0.478429\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-rmse:0.457894\tval-rmse:0.477501\n",
      "\n",
      "fold cv 0 rmsle score is 0.477501\n",
      "[0]\ttrain-rmse:2.17575\tval-rmse:2.17647\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.458824\tval-rmse:0.473939\n",
      "[100]\ttrain-rmse:0.452679\tval-rmse:0.474737\n",
      "Stopping. Best iteration:\n",
      "[43]\ttrain-rmse:0.459512\tval-rmse:0.47388\n",
      "\n",
      "fold cv 1 rmsle score is 0.473880\n",
      "[0]\ttrain-rmse:2.17615\tval-rmse:2.17465\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.459152\tval-rmse:0.470318\n",
      "[100]\ttrain-rmse:0.4531\tval-rmse:0.470924\n",
      "Stopping. Best iteration:\n",
      "[38]\ttrain-rmse:0.4607\tval-rmse:0.470181\n",
      "\n",
      "fold cv 2 rmsle score is 0.470181\n",
      "[0]\ttrain-rmse:2.17647\tval-rmse:2.17367\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.458556\tval-rmse:0.471219\n",
      "[100]\ttrain-rmse:0.452967\tval-rmse:0.47197\n",
      "Stopping. Best iteration:\n",
      "[43]\ttrain-rmse:0.459577\tval-rmse:0.471073\n",
      "\n",
      "fold cv 3 rmsle score is 0.471073\n",
      "[0]\ttrain-rmse:2.17648\tval-rmse:2.17418\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.459325\tval-rmse:0.470103\n",
      "[100]\ttrain-rmse:0.453344\tval-rmse:0.470974\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-rmse:0.459903\tval-rmse:0.469995\n",
      "\n",
      "fold cv 4 rmsle score is 0.469995\n",
      "cv rmsle score is 0.472538\n",
      "it takes 57.084 seconds to perform cross validation\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting xgboost...\")\n",
    "\n",
    "xgb_lv2_outcomes=cross_validate_xgb(xgb_params, lv1_train_df, y_train, lv1_test_df, kf)\n",
    "\n",
    "xgb_lv2_cv=xgb_lv2_outcomes[0]\n",
    "xgb_lv2_train_pred=xgb_lv2_outcomes[1]\n",
    "xgb_lv2_test_pred=xgb_lv2_outcomes[2]\n",
    "\n",
    "xgb_lv2_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_lv2_train_pred)\n",
    "xgb_lv2_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_lv2_test_pred)\n",
    "\n",
    "xgb_lv2_train_pred_df.to_csv('lv2_xgb_train_pred.csv', index=False)\n",
    "xgb_lv2_test_pred_df.to_csv('lv2_xgb_test_pred.csv', index=False)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Level 3 ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv2_lgb_train_pred = pd.read_csv('./lv2_lgb_train_pred.csv')\n",
    "lv2_lgb_test_pred = pd.read_csv('./lv2_lgb_test_pred.csv')\n",
    "\n",
    "lv2_xgb_train_pred = pd.read_csv('./lv2_xgb_train_pred.csv')\n",
    "lv2_xgb_test_pred = pd.read_csv('./lv2_xgb_test_pred.csv')\n",
    "\n",
    "lv2_rfr_train_pred = pd.read_csv('./lv2_rf_train_pred.csv')\n",
    "lv2_rfr_test_pred = pd.read_csv('./lv2_rf_test_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Generate L2 output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['lgb','xgb','rfr']\n",
    "train_pred_df_list=[lv1_lgb_train_pred, lv1_xgb_train_pred, lv1_rfr_train_pred]\n",
    "\n",
    "test_pred_df_list=[lv1_lgb_test_pred, lv1_xgb_test_pred, lv1_rfr_test_pred]\n",
    "\n",
    "lv2_train_df=pd.DataFrame(columns=columns)\n",
    "lv2_test_df=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(columns)):\n",
    "    lv2_train_df[columns[i]]=train_pred_df_list[i]['visitors']\n",
    "    lv2_test_df[columns[i]]=test_pred_df_list[i]['visitors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Level 3 XGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting xgboost...\n",
      "[0]\ttrain-rmse:2.17438\tval-rmse:2.18043\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.463203\tval-rmse:0.480638\n",
      "[100]\ttrain-rmse:0.4599\tval-rmse:0.48115\n",
      "[150]\ttrain-rmse:0.457077\tval-rmse:0.48153\n",
      "Stopping. Best iteration:\n",
      "[50]\ttrain-rmse:0.463203\tval-rmse:0.480638\n",
      "\n",
      "fold cv 0 rmsle score is 0.480638\n",
      "[0]\ttrain-rmse:2.17572\tval-rmse:2.17611\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.464863\tval-rmse:0.476804\n",
      "[100]\ttrain-rmse:0.46098\tval-rmse:0.477157\n",
      "Stopping. Best iteration:\n",
      "[46]\ttrain-rmse:0.465193\tval-rmse:0.476779\n",
      "\n",
      "fold cv 1 rmsle score is 0.476779\n",
      "[0]\ttrain-rmse:2.17601\tval-rmse:2.17422\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.465424\tval-rmse:0.473945\n",
      "[100]\ttrain-rmse:0.461713\tval-rmse:0.474273\n",
      "[150]\ttrain-rmse:0.458824\tval-rmse:0.475009\n",
      "Stopping. Best iteration:\n",
      "[52]\ttrain-rmse:0.465246\tval-rmse:0.473933\n",
      "\n",
      "fold cv 2 rmsle score is 0.473933\n",
      "[0]\ttrain-rmse:2.17628\tval-rmse:2.17486\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.465031\tval-rmse:0.47471\n",
      "[100]\ttrain-rmse:0.461572\tval-rmse:0.47527\n",
      "[150]\ttrain-rmse:0.458427\tval-rmse:0.475674\n",
      "Stopping. Best iteration:\n",
      "[52]\ttrain-rmse:0.464852\tval-rmse:0.474688\n",
      "\n",
      "fold cv 3 rmsle score is 0.474688\n",
      "[0]\ttrain-rmse:2.17641\tval-rmse:2.17387\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[50]\ttrain-rmse:0.466215\tval-rmse:0.473189\n",
      "[100]\ttrain-rmse:0.462812\tval-rmse:0.473558\n",
      "[150]\ttrain-rmse:0.459855\tval-rmse:0.474027\n",
      "Stopping. Best iteration:\n",
      "[55]\ttrain-rmse:0.46574\tval-rmse:0.473125\n",
      "\n",
      "fold cv 4 rmsle score is 0.473125\n",
      "cv rmsle score is 0.475844\n",
      "it takes 40.820 seconds to perform cross validation\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting xgboost...\")\n",
    "\n",
    "xgb_lv3_outcomes=cross_validate_xgb(xgb_params, lv2_train_df, y_train, lv2_test_df, kf)\n",
    "\n",
    "xgb_lv3_cv=xgb_lv3_outcomes[0]\n",
    "xgb_lv3_train_pred=xgb_lv3_outcomes[1]\n",
    "xgb_lv3_test_pred=xgb_lv3_outcomes[2]\n",
    "\n",
    "xgb_lv3_train_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_lv3_train_pred)\n",
    "xgb_lv3_test_pred_df=pd.DataFrame(columns=['visitors'], data=xgb_lv3_test_pred)\n",
    "\n",
    "xgb_lv3_train_pred_df.to_csv('lv3_xgb_train_pred.csv', index=False)\n",
    "xgb_lv3_test_pred_df.to_csv('lv3_xgb_test_pred.csv', index=False)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv3_xgb_train_pred = xgb_lv3_train_pred_df.copy()\n",
    "lv3_xgb_train_pred.to_csv('lv3_xgb_train_pred.csv', index=False)\n",
    "\n",
    "lv3_xgb_test_pred = xgb_lv3_test_pred_df.copy()\n",
    "lv3_xgb_test_pred.to_csv('lv3_xgb_test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['visitors'] = xgb_lv2_test_pred_df.values\n",
    "sub = test[['id','visitors']].copy()\n",
    "sub1 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hklee\n",
    "# https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st/code\n",
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('../../../mltestdata/05_recruit/*.csv')}\n",
    "\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "wkend_holidays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) # cumbersome, should be better ways.\n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), \n",
    "    how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission_rs_recruit_v17_stacking_02_01.csv', index=False)\n",
    "\n",
    "# gw_flag\n",
    "# xgb\n",
    "# Bopt\n",
    "# weight\n",
    "# Stacking\n",
    "# Local 0.475844\n",
    "# PubLB 0.480\n",
    "# PriLB 0.581"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
